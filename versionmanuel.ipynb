{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Iniciando anÃ¡lisis de TED Talks\n",
            "ðŸ“Š Dataset: ted_talks_en.csv\n",
            "ðŸŽ¯ Objetivo: ExtracciÃ³n de informaciÃ³n + Modelos ML\n",
            "OK - Sistema de progreso en tiempo real cargado\n",
            "Cargando mÃ³dulos del proyecto TED Talks...\n",
            "âœ“ MÃ³dulo de configuraciÃ³n del ambiente cargado\n",
            "OK - Sistema de progreso en tiempo real cargado\n",
            "Cargando mÃ³dulos del proyecto TED Talks...\n",
            "âœ“ MÃ³dulo de configuraciÃ³n del ambiente cargado\n",
            "âœ“ MÃ³dulo de limpieza de datos cargado\n",
            "âœ“ MÃ³dulo de limpieza de datos cargado\n",
            "âœ“ MÃ³dulo de procesamiento NLP cargado\n",
            "âœ“ MÃ³dulo de procesamiento NLP cargado\n",
            "âœ“ MÃ³dulo de visualizaciÃ³n cargado\n",
            "âœ“ MÃ³dulo de machine learning cargado\n",
            "ðŸŽ¯ MÃ³dulos TED Talks cargados correctamente\n",
            "ðŸ“š Uso recomendado:\n",
            "   from modules import quick_start\n",
            "   analyzer, results = quick_start('ted_talks_en.csv')\n",
            "==================================================\n",
            "âœ… MÃ³dulos cargados correctamente\n",
            "âœ“ MÃ³dulo de visualizaciÃ³n cargado\n",
            "âœ“ MÃ³dulo de machine learning cargado\n",
            "ðŸŽ¯ MÃ³dulos TED Talks cargados correctamente\n",
            "ðŸ“š Uso recomendado:\n",
            "   from modules import quick_start\n",
            "   analyzer, results = quick_start('ted_talks_en.csv')\n",
            "==================================================\n",
            "âœ… MÃ³dulos cargados correctamente\n"
          ]
        }
      ],
      "source": [
        "# === ANALISIS DE POPULARIDAD DE TED TALKS ===\n",
        "# Aplicacion de Extraccion de Informacion y Comparacion de Modelos ML\n",
        "\n",
        "print(\"Iniciando analisis de TED Talks\")\n",
        "print(\"Dataset: ted_talks_en.csv\")\n",
        "print(\"Objetivo: Extraccion de informacion + Modelos ML\")\n",
        "\n",
        "# Importar la clase principal que controla todo el flujo\n",
        "from modules import TedTalkAnalyzer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Modulos cargados correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ§ª EJECUTANDO PRUEBA RÃPIDA DEL SISTEMA\n",
            "Esta celda verifica que todo estÃ© configurado correctamente\n",
            "=======================================================\n",
            "Iniciando: Iniciando verificaciÃ³n rÃ¡pida del sistema\n",
            "Tiempo de inicio: 04:29:58\n",
            "==================================================\n",
            "[1/4] (25.0%) Verificando imports bÃ¡sicos... OK\n",
            "[04:29:58] LibrerÃ­as bÃ¡sicas: OK\n",
            "[2/4] (50.0%) Verificando acceso a datos... OK\n",
            "[04:29:58] LibrerÃ­as bÃ¡sicas: OK\n",
            "[2/4] (50.0%) Verificando acceso a datos... OK\n",
            " OK\n",
            "[04:29:59] Dataset cargado: 4,005 filas\n",
            "[3/4] (75.0%) Verificando mÃ³dulos del proyecto...[04:29:59] Dataset cargado: 4,005 filas\n",
            "[3/4] (75.0%) Verificando mÃ³dulos del proyecto... OK\n",
            "[04:29:59] MÃ³dulos disponibles: 4/4\n",
            "[4/4] (100.0%) Verificando configuraciÃ³n del ambiente... OK\n",
            "[04:29:59] MÃ³dulos disponibles: 4/4\n",
            "[4/4] (100.0%) Verificando configuraciÃ³n del ambiente... OK\n",
            "[04:29:59] TextBlob: OK\n",
            "\n",
            "==================================================\n",
            "Estado: VerificaciÃ³n completada\n",
            "Tiempo total: 1.1 segundos\n",
            "Finalizado: 04:29:59\n",
            "Tiempo promedio por paso: 0.3s\n",
            "\n",
            "ðŸŽ¯ RESULTADO DE LA PRUEBA:\n",
            "========================================\n",
            "âœ… LibrerÃ­as bÃ¡sicas: Funcionando\n",
            "âœ… Acceso a datos: OK\n",
            "âœ… MÃ³dulos del proyecto: 4/4 disponibles\n",
            "ðŸ• VerificaciÃ³n completada: 04:29:59\n",
            "\n",
            "ðŸ’¡ Puedes proceder con el anÃ¡lisis completo\n",
            "\n",
            "ðŸš€ Â¡Todo listo! Puedes continuar con el anÃ¡lisis completo\n",
            "=======================================================\n",
            " OK\n",
            "[04:29:59] TextBlob: OK\n",
            "\n",
            "==================================================\n",
            "Estado: VerificaciÃ³n completada\n",
            "Tiempo total: 1.1 segundos\n",
            "Finalizado: 04:29:59\n",
            "Tiempo promedio por paso: 0.3s\n",
            "\n",
            "ðŸŽ¯ RESULTADO DE LA PRUEBA:\n",
            "========================================\n",
            "âœ… LibrerÃ­as bÃ¡sicas: Funcionando\n",
            "âœ… Acceso a datos: OK\n",
            "âœ… MÃ³dulos del proyecto: 4/4 disponibles\n",
            "ðŸ• VerificaciÃ³n completada: 04:29:59\n",
            "\n",
            "ðŸ’¡ Puedes proceder con el anÃ¡lisis completo\n",
            "\n",
            "ðŸš€ Â¡Todo listo! Puedes continuar con el anÃ¡lisis completo\n",
            "=======================================================\n"
          ]
        }
      ],
      "source": [
        "# === CREAR INSTANCIA DEL ANALIZADOR ===\n",
        "\n",
        "print(\"Creando instancia del analizador TED Talks...\")\n",
        "\n",
        "# Crear instancia de la clase principal\n",
        "analyzer = TedTalkAnalyzer()\n",
        "\n",
        "print(\"Analizador creado correctamente\")\n",
        "print(\"Metodos disponibles:\")\n",
        "print(\"- setup_environment(): Configurar ambiente\")\n",
        "print(\"- load_data(): Cargar datos\")\n",
        "print(\"- clean_data(): Limpiar datos\")\n",
        "print(\"- process_nlp_features(): Procesar NLP\")\n",
        "print(\"- train_models(): Entrenar modelos ML\")\n",
        "print(\"- create_visualizations(): Crear graficos\")\n",
        "print(\"- run_complete_analysis(): Ejecutar todo automaticamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ• INICIO: 04:29:59\n",
            "âš™ï¸  Configurando ambiente y dependencias...\n",
            "ðŸ“Š Esto puede tomar 2-5 minutos la primera vez\n",
            "==================================================\n",
            "=== CONFIGURACION DEL AMBIENTE ===\n",
            "Tiempo estimado: 2-5 minutos\n",
            "\n",
            "PASO 1/3: Instalando 8 paquetes esenciales...\n",
            "  [1/8] Instalando pandas>=1.3.0...Instalando pandas>=1.3.0... OK\n",
            "  [2/8] Instalando numpy>=1.21.0... OK\n",
            "  [2/8] Instalando numpy>=1.21.0... OK\n",
            "  [3/8] Instalando scikit-learn>=1.0.0... OK\n",
            "  [3/8] Instalando scikit-learn>=1.0.0... OK\n",
            "  [4/8] Instalando matplotlib>=3.4.0... OK\n",
            "  [4/8] Instalando matplotlib>=3.4.0... OK\n",
            "  [5/8] Instalando seaborn>=0.11.0... OK\n",
            "  [5/8] Instalando seaborn>=0.11.0... OK\n",
            "  [6/8] Instalando nltk>=3.7... OK\n",
            "  [6/8] Instalando nltk>=3.7... OK\n",
            "  [7/8] Instalando textblob>=0.17.0... OK\n",
            "  [7/8] Instalando textblob>=0.17.0... OK\n",
            "  [8/8] Instalando tqdm>=4.64.0... OK\n",
            "  [8/8] Instalando tqdm>=4.64.0... OK\n",
            "\n",
            "Paquetes esenciales: 8/8 instalados\n",
            "\n",
            "PASO 2/3: Instalando 3 paquetes opcionales...\n",
            "  [1/3] Instalando plotly>=5.0.0... OK\n",
            "\n",
            "Paquetes esenciales: 8/8 instalados\n",
            "\n",
            "PASO 2/3: Instalando 3 paquetes opcionales...\n",
            "  [1/3] Instalando plotly>=5.0.0... OK\n",
            "  [2/3] Instalando spacy>=3.4.0... OK\n",
            "  [2/3] Instalando spacy>=3.4.0... OK\n",
            "  [3/3] Instalando wordcloud>=1.8.0... OK\n",
            "  [3/3] Instalando wordcloud>=1.8.0... OK\n",
            "\n",
            "Paquetes opcionales: 3/3 instalados\n",
            "\n",
            "PASO 3/3: Configurando modelos de NLP...\n",
            "  Descargando datos NLTK... OK\n",
            "\n",
            "Paquetes opcionales: 3/3 instalados\n",
            "\n",
            "PASO 3/3: Configurando modelos de NLP...\n",
            "  Descargando datos NLTK... OK\n",
            "  Verificando spaCy... OK\n",
            "  Verificando spaCy... OK\n",
            "\n",
            "CONFIGURACION COMPLETADA\n",
            "========================================\n",
            "\n",
            "â±ï¸  Tiempo total: 25.3 segundos\n",
            "ðŸ• COMPLETADO: 04:30:25\n",
            "==================================================\n",
            " OK\n",
            "\n",
            "CONFIGURACION COMPLETADA\n",
            "========================================\n",
            "\n",
            "â±ï¸  Tiempo total: 25.3 segundos\n",
            "ðŸ• COMPLETADO: 04:30:25\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# === CONFIGURACION DEL AMBIENTE ===\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"INICIO:\", datetime.now().strftime(\"%H:%M:%S\"))\n",
        "print(\"Configurando ambiente y dependencias...\")\n",
        "print(\"Esto puede tomar 2-5 minutos la primera vez\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Configurar ambiente usando el metodo del analizador\n",
        "start_time = time.time()\n",
        "analyzer.setup_environment()\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed = end_time - start_time\n",
        "print(f\"\\nTiempo total: {elapsed:.1f} segundos\")\n",
        "print(f\"COMPLETADO:\", datetime.now().strftime(\"%H:%M:%S\"))\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ§ª Verificando que los mÃ³dulos funcionan correctamente...\n",
            "  ðŸ“Š pandas... âœ…\n",
            "  ðŸ”¢ numpy... âœ…\n",
            "  ðŸ¤– sklearn... âœ…\n",
            "  ðŸ“ˆ matplotlib... âœ…\n",
            "  ðŸ”¤ nltk... âœ…\n",
            "  ðŸŽ¯ textblob... âœ…\n",
            "\n",
            "âœ… ConfiguraciÃ³n verificada - Â¡Todo listo para continuar!\n",
            "==================================================\n",
            " âœ…\n",
            "  ðŸ”¢ numpy... âœ…\n",
            "  ðŸ¤– sklearn... âœ…\n",
            "  ðŸ“ˆ matplotlib... âœ…\n",
            "  ðŸ”¤ nltk... âœ…\n",
            "  ðŸŽ¯ textblob... âœ…\n",
            "\n",
            "âœ… ConfiguraciÃ³n verificada - Â¡Todo listo para continuar!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# === CARGA DE DATOS ===\n",
        "\n",
        "print(\"Cargando dataset ted_talks_en.csv...\")\n",
        "\n",
        "# Cargar datos usando el metodo del analizador\n",
        "analyzer.load_data('ted_talks_en.csv')\n",
        "\n",
        "# Mostrar informacion basica\n",
        "if analyzer.data_original is not None:\n",
        "    print(f\"Dataset cargado exitosamente\")\n",
        "    print(f\"Filas: {analyzer.data_original.shape[0]:,}\")\n",
        "    print(f\"Columnas: {analyzer.data_original.shape[1]}\")\n",
        "    print(f\"Memoria utilizada: {analyzer.data_original.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # Mostrar primeras columnas\n",
        "    print(\"\\nColumnas disponibles:\")\n",
        "    for i, col in enumerate(analyzer.data_original.columns):\n",
        "        print(f\"  {i+1}. {col}\")\n",
        "else:\n",
        "    print(\"ERROR: No se pudo cargar el dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === LIMPIEZA DE DATOS ===\n",
        "\n",
        "print(\"Aplicando limpieza profesional de datos...\")\n",
        "\n",
        "# Limpiar datos usando el metodo del analizador\n",
        "analyzer.clean_data()\n",
        "\n",
        "# Mostrar resultados de la limpieza\n",
        "if analyzer.data_clean is not None:\n",
        "    original_count = analyzer.data_original.shape[0]\n",
        "    clean_count = analyzer.data_clean.shape[0]\n",
        "    removed_count = original_count - clean_count\n",
        "    \n",
        "    print(f\"\\nResultados de la limpieza:\")\n",
        "    print(f\"  Filas originales: {original_count:,}\")\n",
        "    print(f\"  Filas despues de limpieza: {clean_count:,}\")\n",
        "    print(f\"  Filas eliminadas: {removed_count:,} ({removed_count/original_count*100:.1f}%)\")\n",
        "    \n",
        "    # Mostrar categorias de popularidad creadas\n",
        "    if 'popularity_category' in analyzer.data_clean.columns:\n",
        "        print(\"\\nCategorias de popularidad:\")\n",
        "        categories = analyzer.data_clean['popularity_category'].value_counts().sort_index()\n",
        "        for category, count in categories.items():\n",
        "            print(f\"  {category}: {count:,} videos\")\n",
        "            \n",
        "    # Mostrar calidad de datos\n",
        "    if 'data_cleaning' in analyzer.results:\n",
        "        quality_score = analyzer.results['data_cleaning']['quality_results']['quality_score']\n",
        "        print(f\"\\nPuntuacion de calidad de datos: {quality_score:.2f}/10\")\n",
        "else:\n",
        "    print(\"ERROR: No se pudo limpiar el dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === EXTRACCION DE INFORMACION CON NLP ===\n",
        "\n",
        "print(\"Aplicando tecnicas de extraccion de informacion...\")\n",
        "print(\"Procesando: sentimientos, entidades nombradas, caracteristicas textuales\")\n",
        "\n",
        "# Procesar caracteristicas NLP usando el metodo del analizador\n",
        "analyzer.process_nlp_features(text_column='transcript_clean')\n",
        "\n",
        "# Mostrar caracteristicas extraidas\n",
        "if analyzer.data_processed is not None:\n",
        "    print(f\"\\nExtraccion de informacion completada\")\n",
        "    print(f\"Dataset procesado: {analyzer.data_processed.shape}\")\n",
        "    \n",
        "    # Identificar caracteristicas NLP creadas\n",
        "    nlp_features = [col for col in analyzer.data_processed.columns if \n",
        "                   col.startswith(('sentiment_', 'text_', 'person_', 'org_', 'gpe_'))]\n",
        "    \n",
        "    print(f\"\\nCaracteristicas NLP extraidas: {len(nlp_features)}\")\n",
        "    print(\"Tipos de informacion extraida:\")\n",
        "    \n",
        "    # Agrupar por tipo\n",
        "    sentiment_features = [f for f in nlp_features if f.startswith('sentiment_')]\n",
        "    text_features = [f for f in nlp_features if f.startswith('text_')]\n",
        "    entity_features = [f for f in nlp_features if f.startswith(('person_', 'org_', 'gpe_'))]\n",
        "    \n",
        "    if sentiment_features:\n",
        "        print(f\"  Analisis de sentimientos: {len(sentiment_features)} caracteristicas\")\n",
        "    if text_features:\n",
        "        print(f\"  Caracteristicas textuales: {len(text_features)} caracteristicas\") \n",
        "    if entity_features:\n",
        "        print(f\"  Entidades nombradas: {len(entity_features)} caracteristicas\")\n",
        "        \n",
        "    # Mostrar estadisticas de muestra procesada\n",
        "    if 'nlp_processing' in analyzer.results:\n",
        "        sample_size = analyzer.results['nlp_processing']['sample_size']\n",
        "        print(f\"\\nMuestra procesada: {sample_size} registros\")\n",
        "else:\n",
        "    print(\"ERROR: No se pudo procesar las caracteristicas NLP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-03T07:03:25.803244Z",
          "start_time": "2025-08-03T07:03:25.143615Z"
        },
        "cell_id": "5abe3fcf07e4410ea49ff1de3fca1b50",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 95512,
        "execution_start": 1754262986754,
        "source_hash": "ecbd79b7"
      },
      "outputs": [],
      "source": [
        "# === ENTRENAMIENTO Y COMPARACION DE MODELOS ML ===\n",
        "\n",
        "print(\"Entrenando y comparando modelos de Machine Learning...\")\n",
        "print(\"Objetivo: F1-score > 0.78\")\n",
        "\n",
        "# Entrenar modelos usando el metodo del analizador\n",
        "analyzer.train_models(text_column='transcript_clean', target_column='popularity_numeric')\n",
        "\n",
        "# Mostrar resultados de los modelos\n",
        "if 'machine_learning' in analyzer.results:\n",
        "    ml_results = analyzer.results['machine_learning']['model_results']\n",
        "    classifier = analyzer.results['machine_learning']['classifier']\n",
        "    \n",
        "    print(\"\\nRESULTADOS DE MODELOS:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Mostrar resultados de cada modelo\n",
        "    for model_name, results in ml_results.items():\n",
        "        if results is not None:\n",
        "            print(f\"\\n{model_name}:\")\n",
        "            print(f\"  Accuracy:  {results['accuracy']:.4f}\")\n",
        "            print(f\"  Precision: {results['precision']:.4f}\")\n",
        "            print(f\"  Recall:    {results['recall']:.4f}\")\n",
        "            print(f\"  F1-Score:  {results['f1_score']:.4f}\")\n",
        "            \n",
        "            # Verificar si cumple objetivo\n",
        "            objetivo_cumplido = \"SI\" if results['f1_score'] > 0.78 else \"NO\"\n",
        "            print(f\"  Objetivo F1>0.78: {objetivo_cumplido}\")\n",
        "    \n",
        "    # Identificar mejor modelo\n",
        "    best_model_name, best_model, best_score = classifier.get_best_model()\n",
        "    print(f\"\\nMEJOR MODELO: {best_model_name}\")\n",
        "    print(f\"F1-Score: {best_score:.4f}\")\n",
        "    \n",
        "    if best_score > 0.78:\n",
        "        print(\"Objetivo cumplido! F1-Score > 0.78\")\n",
        "    else:\n",
        "        print(\"Objetivo no cumplido. Considerar mas datos o mejores caracteristicas.\")\n",
        "        \n",
        "    # Guardar el mejor modelo para referencia\n",
        "    analyzer.best_model_name = best_model_name\n",
        "    analyzer.best_f1_score = best_score\n",
        "else:\n",
        "    print(\"ERROR: No se pudieron entrenar los modelos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-02T20:23:05.092879Z",
          "start_time": "2025-08-02T20:23:05.090755Z"
        },
        "cell_id": "e311e55f07eb4774aef2d27d4ba3f105",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 5768,
        "execution_start": 1754263082313,
        "source_hash": "f325302b"
      },
      "outputs": [],
      "source": [
        "# === METRICAS DE RENDIMIENTO Y VISUALIZACIONES ===\n",
        "\n",
        "print(\"Generando metricas de rendimiento y visualizaciones...\")\n",
        "\n",
        "# Crear visualizaciones usando el metodo del analizador\n",
        "analyzer.create_visualizations()\n",
        "\n",
        "# Mostrar informacion sobre las visualizaciones creadas\n",
        "if 'visualizations' in analyzer.results:\n",
        "    print(\"\\nVisualizaciones creadas exitosamente:\")\n",
        "    \n",
        "    # Si hay un clasificador disponible, mostrar importancia de caracteristicas\n",
        "    if hasattr(analyzer, 'best_model_name') and 'machine_learning' in analyzer.results:\n",
        "        classifier = analyzer.results['machine_learning']['classifier']\n",
        "        \n",
        "        print(f\"\\nImportancia de caracteristicas del mejor modelo ({analyzer.best_model_name}):\")\n",
        "        try:\n",
        "            feature_importance = classifier.get_feature_importance(analyzer.best_model_name, top_n=10)\n",
        "            for i, (feature, importance) in enumerate(feature_importance, 1):\n",
        "                print(f\"  {i:2d}. {feature}: {importance:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  No se pudo obtener importancia de caracteristicas: {e}\")\n",
        "    \n",
        "    print(\"\\nTipos de visualizaciones disponibles:\")\n",
        "    print(\"  - Distribucion de datos\")\n",
        "    print(\"  - Correlaciones entre variables\")\n",
        "    print(\"  - Metricas de modelos ML\")\n",
        "    print(\"  - Matrices de confusion\")\n",
        "    print(\"  - Comparacion de rendimiento\")\n",
        "else:\n",
        "    print(\"ERROR: No se pudieron crear las visualizaciones\")\n",
        "\n",
        "print(\"\\nAnalisis completo finalizado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ba14dbd4adcd427685627c07bc45b6ec",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 578,
        "execution_start": 1754263088133,
        "source_hash": "8f5ea635"
      },
      "outputs": [],
      "source": [
        "# === RESUMEN FINAL Y CONCLUSIONES ===\n",
        "\n",
        "print(\"RESUMEN FINAL DEL ANALISIS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Usar el metodo de resumen final del analizador\n",
        "analyzer.print_final_summary()\n",
        "\n",
        "# Informacion adicional sobre el estado del proyecto\n",
        "print(\"\\nESTADO DEL PROYECTO:\")\n",
        "if hasattr(analyzer, 'best_f1_score'):\n",
        "    if analyzer.best_f1_score > 0.78:\n",
        "        print(\"EXITOSO - Objetivo de F1 > 0.78 cumplido\")\n",
        "    else:\n",
        "        print(\"REQUIERE MEJORAS - Objetivo no cumplido\")\n",
        "        print(\"Recomendaciones:\")\n",
        "        print(\"  - Aumentar tamano de la muestra\")\n",
        "        print(\"  - Agregar mas caracteristicas NLP\")\n",
        "        print(\"  - Probar diferentes algoritmos\")\n",
        "        print(\"  - Mejorar limpieza de datos\")\n",
        "else:\n",
        "    print(\"INCOMPLETO - No se entrenaron modelos\")\n",
        "\n",
        "print(\"\\nACCESO A RESULTADOS:\")\n",
        "print(\"- analyzer.data_original: Dataset original\")\n",
        "print(\"- analyzer.data_clean: Dataset limpio\")\n",
        "print(\"- analyzer.data_processed: Dataset con caracteristicas NLP\")\n",
        "print(\"- analyzer.results: Diccionario con todos los resultados\")\n",
        "\n",
        "# Mostrar tamanos de datos procesados\n",
        "if analyzer.data_original is not None:\n",
        "    print(f\"\\nTAMANOS DE DATOS:\")\n",
        "    print(f\"  Original: {analyzer.data_original.shape}\")\n",
        "if analyzer.data_clean is not None:\n",
        "    print(f\"  Limpio: {analyzer.data_clean.shape}\")\n",
        "if analyzer.data_processed is not None:\n",
        "    print(f\"  Procesado: {analyzer.data_processed.shape}\")\n",
        "\n",
        "print(\"\\nANALISIS COMPLETADO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === OPCION: EJECUCION AUTOMATICA COMPLETA ===\n",
        "\n",
        "print(\"OPCION ALTERNATIVA: Ejecutar todo el analisis automaticamente\")\n",
        "print(\"Esta opcion ejecuta todos los pasos en una sola celda\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Descomenta las siguientes lineas para ejecutar todo automaticamente:\n",
        "\n",
        "# print(\"Iniciando analisis automatico...\")\n",
        "# analyzer_auto = TedTalkAnalyzer()\n",
        "# results = analyzer_auto.run_complete_analysis('ted_talks_en.csv')\n",
        "# print(\"Analisis automatico completado\")\n",
        "\n",
        "print(\"\\nEsta opcion automatica ejecuta:\")\n",
        "print(\"  1. Configuracion del ambiente\")\n",
        "print(\"  2. Carga de datos\") \n",
        "print(\"  3. Limpieza de datos\")\n",
        "print(\"  4. Extraccion de informacion NLP\")\n",
        "print(\"  5. Entrenamiento de modelos ML\")\n",
        "print(\"  6. Creacion de visualizaciones\")\n",
        "print(\"  7. Resumen final\")\n",
        "\n",
        "print(\"\\nResultado esperado: F1-score > 0.78 en el mejor modelo\")\n",
        "print(\"Tiempo estimado: 5-10 minutos\")\n",
        "print(\"Dataset optimizado para extraccion de informacion de ted_talks_en.csv\")\n",
        "\n",
        "print(\"\\nPara usar esta opcion:\")\n",
        "print(\"1. Descomenta las lineas 7-10\")\n",
        "print(\"2. Ejecuta esta celda\")\n",
        "print(\"3. Los resultados estaran en 'analyzer_auto' y 'results'\")"
      ]
    }
  ],
  "metadata": {
    "deepnote_notebook_id": "9ef24892143a426ca3c75c3ddd0a2b31",
    "kernelspec": {
      "display_name": "cloudspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
