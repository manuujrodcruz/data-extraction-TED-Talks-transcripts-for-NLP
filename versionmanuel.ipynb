{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Iniciando anÃ¡lisis de TED Talks\n",
            "ðŸ“Š Dataset: ted_talks_en.csv\n",
            "ðŸŽ¯ Objetivo: ExtracciÃ³n de informaciÃ³n + Modelos ML\n",
            "ðŸ“Š Cargando mÃ³dulos del proyecto TED Talks...\n",
            "âœ“ MÃ³dulo de configuraciÃ³n del ambiente cargado\n",
            "âœ“ MÃ³dulo de limpieza de datos cargado\n",
            "âœ“ MÃ³dulo de procesamiento NLP cargado\n",
            "âœ“ MÃ³dulo de visualizaciÃ³n cargado\n",
            "âœ“ MÃ³dulo de machine learning cargado\n",
            "ðŸŽ¯ MÃ³dulos TED Talks cargados correctamente\n",
            "ðŸ“š Uso recomendado:\n",
            "   from modules import quick_start\n",
            "   analyzer, results = quick_start('ted_talks_en.csv')\n",
            "==================================================\n",
            "âœ… MÃ³dulos cargados correctamente\n"
          ]
        }
      ],
      "source": [
        "# === PROYECTO DE ANÃLISIS DE POPULARIDAD DE TED TALKS ===\n",
        "# AplicaciÃ³n de ExtracciÃ³n de InformaciÃ³n y ComparaciÃ³n de Modelos ML\n",
        "\n",
        "print(\"ðŸš€ Iniciando anÃ¡lisis de TED Talks\")\n",
        "print(\"ðŸ“Š Dataset: ted_talks_en.csv\")\n",
        "print(\"ðŸŽ¯ Objetivo: ExtracciÃ³n de informaciÃ³n + Modelos ML\")\n",
        "\n",
        "# Importar mÃ³dulos del proyecto\n",
        "from modules import TedTalkAnalyzer\n",
        "from modules.environment_setup import setup_environment\n",
        "from modules.data_cleaner import clean_dataset_professional\n",
        "from modules.nlp_processor import process_text_features\n",
        "from modules.ml_models import create_ml_pipeline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… MÃ³dulos cargados correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CONFIGURACIÃ“N DEL AMBIENTE ===\n",
        "\n",
        "print(\"\udd27 Configurando ambiente y dependencias...\")\n",
        "\n",
        "# Configurar ambiente automÃ¡ticamente\n",
        "setup_environment()\n",
        "\n",
        "print(\"âœ… Ambiente configurado correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CARGA Y LIMPIEZA DE DATOS ===\n",
        "\n",
        "print(\"\udcc2 Cargando dataset ted_talks_en.csv...\")\n",
        "\n",
        "# Cargar dataset\n",
        "df_original = pd.read_csv('ted_talks_en.csv')\n",
        "print(f\"Dataset original: {df_original.shape[0]} filas x {df_original.shape[1]} columnas\")\n",
        "\n",
        "# Limpieza profesional de datos (eliminar outliers, crear categorÃ­as)\n",
        "print(\"\\nðŸ§¹ Aplicando limpieza profesional...\")\n",
        "df_clean, cleaning_log = clean_dataset_professional(df_original)\n",
        "\n",
        "print(f\"Dataset limpio: {df_clean.shape[0]} filas x {df_clean.shape[1]} columnas\")\n",
        "print(f\"Filas eliminadas: {df_original.shape[0] - df_clean.shape[0]}\")\n",
        "\n",
        "# Mostrar categorÃ­as de popularidad creadas\n",
        "print(\"\\nCategorÃ­as de popularidad:\")\n",
        "print(df_clean['popularity_category'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === EXTRACCIÃ“N DE INFORMACIÃ“N CON NLP ===\n",
        "\n",
        "print(\"ðŸ”¤ Aplicando tÃ©cnicas de extracciÃ³n de informaciÃ³n...\")\n",
        "print(\"ðŸ“Š Procesando: sentimientos, entidades nombradas, caracterÃ­sticas textuales\")\n",
        "\n",
        "# Procesar caracterÃ­sticas NLP en una muestra para velocidad\n",
        "sample_size = min(200, len(df_clean))\n",
        "df_sample = df_clean.head(sample_size).copy()\n",
        "\n",
        "print(f\"Procesando muestra de {sample_size} registros para extracciÃ³n de informaciÃ³n...\")\n",
        "\n",
        "# Aplicar procesamiento NLP completo\n",
        "df_with_nlp = process_text_features(df_sample, text_column='transcript_clean')\n",
        "\n",
        "# Mostrar caracterÃ­sticas extraÃ­das\n",
        "nlp_features = [col for col in df_with_nlp.columns if \n",
        "               col.startswith(('sentiment_', 'text_', 'person_', 'org_', 'gpe_'))]\n",
        "\n",
        "print(f\"\\nâœ… CaracterÃ­sticas NLP extraÃ­das: {len(nlp_features)}\")\n",
        "print(\"Tipos de informaciÃ³n extraÃ­da:\")\n",
        "for feature in nlp_features[:10]:  # Mostrar solo primeras 10\n",
        "    print(f\"  - {feature}\")\n",
        "\n",
        "if len(nlp_features) > 10:\n",
        "    print(f\"  ... y {len(nlp_features) - 10} mÃ¡s\")\n",
        "\n",
        "print(f\"\\nDataset con informaciÃ³n extraÃ­da: {df_with_nlp.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-03T07:03:25.803244Z",
          "start_time": "2025-08-03T07:03:25.143615Z"
        },
        "cell_id": "5abe3fcf07e4410ea49ff1de3fca1b50",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 95512,
        "execution_start": 1754262986754,
        "source_hash": "ecbd79b7"
      },
      "outputs": [],
      "source": [
        "# === ENTRENAMIENTO Y COMPARACIÃ“N DE MODELOS ML ===\n",
        "\n",
        "print(\"ðŸ¤– Entrenando y comparando modelos de Machine Learning...\")\n",
        "print(\"ðŸŽ¯ Objetivo: F1-score > 0.78\")\n",
        "\n",
        "# Crear pipeline completo de ML usando los datos procesados\n",
        "classifier, ml_results = create_ml_pipeline(\n",
        "    df_with_nlp, \n",
        "    text_column='transcript_clean',\n",
        "    target_column='popularity_numeric'\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ“Š RESULTADOS DE MODELOS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Mostrar resultados de cada modelo\n",
        "for model_name, results in ml_results.items():\n",
        "    if results is not None:\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(f\"  Accuracy:  {results['accuracy']:.4f}\")\n",
        "        print(f\"  Precision: {results['precision']:.4f}\")\n",
        "        print(f\"  Recall:    {results['recall']:.4f}\")\n",
        "        print(f\"  F1-Score:  {results['f1_score']:.4f}\")\n",
        "        \n",
        "        # Verificar si cumple objetivo\n",
        "        objetivo_cumplido = \"âœ…\" if results['f1_score'] > 0.78 else \"âŒ\"\n",
        "        print(f\"  Objetivo F1>0.78: {objetivo_cumplido}\")\n",
        "\n",
        "# Identificar mejor modelo\n",
        "best_model_name, best_model, best_score = classifier.get_best_model()\n",
        "print(f\"\\nðŸ† MEJOR MODELO: {best_model_name}\")\n",
        "print(f\"ðŸ“ˆ F1-Score: {best_score:.4f}\")\n",
        "\n",
        "if best_score > 0.78:\n",
        "    print(\"ðŸŽ‰ Â¡Objetivo cumplido! F1-Score > 0.78\")\n",
        "else:\n",
        "    print(\"âš ï¸ Objetivo no cumplido. Considerar mÃ¡s datos o mejores caracterÃ­sticas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-02T20:23:05.092879Z",
          "start_time": "2025-08-02T20:23:05.090755Z"
        },
        "cell_id": "e311e55f07eb4774aef2d27d4ba3f105",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 5768,
        "execution_start": 1754263082313,
        "source_hash": "f325302b"
      },
      "outputs": [],
      "source": [
        "# === MÃ‰TRICAS DE RENDIMIENTO Y VISUALIZACIONES ===\n",
        "\n",
        "print(\"ðŸ“Š Generando mÃ©tricas de rendimiento y visualizaciones...\")\n",
        "\n",
        "# Mostrar importancia de caracterÃ­sticas del mejor modelo\n",
        "feature_importance = classifier.get_feature_importance(best_model_name, top_n=15)\n",
        "\n",
        "# Crear visualizaciones de evaluaciÃ³n (matrices de confusiÃ³n, comparaciÃ³n de mÃ©tricas)\n",
        "y_test = None  # Se obtiene internamente del clasificador\n",
        "classifier.create_evaluation_plots(y_test)\n",
        "\n",
        "# Visualizaciones de datos usando el mÃ³dulo visualizer\n",
        "from modules.visualizer import create_data_overview_plots, print_summary_statistics\n",
        "\n",
        "print(\"\\nðŸ“ˆ EstadÃ­sticas del dataset procesado:\")\n",
        "print_summary_statistics(df_with_nlp)\n",
        "\n",
        "print(\"\\nðŸ“Š Creando visualizaciones de resumen...\")\n",
        "create_data_overview_plots(df_with_nlp)\n",
        "\n",
        "print(\"âœ… AnÃ¡lisis completo finalizado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ba14dbd4adcd427685627c07bc45b6ec",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 578,
        "execution_start": 1754263088133,
        "source_hash": "8f5ea635"
      },
      "outputs": [],
      "source": [
        "# === CONCLUSIONES Y RECOMENDACIONES ===\n",
        "\n",
        "print(\"ðŸ“‹ CONCLUSIONES DEL ANÃLISIS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Resumen de datos procesados\n",
        "original_count = df_original.shape[0]\n",
        "clean_count = df_clean.shape[0]\n",
        "outliers_removed = original_count - clean_count\n",
        "\n",
        "print(f\"ðŸ“Š Datos procesados:\")\n",
        "print(f\"  - Registros originales: {original_count:,}\")\n",
        "print(f\"  - Registros despuÃ©s de limpieza: {clean_count:,}\")\n",
        "print(f\"  - Outliers eliminados: {outliers_removed:,} ({outliers_removed/original_count*100:.1f}%)\")\n",
        "\n",
        "# Resumen de extracciÃ³n de informaciÃ³n\n",
        "nlp_features_count = len([col for col in df_with_nlp.columns if \n",
        "                         col.startswith(('sentiment_', 'text_', 'person_', 'org_'))])\n",
        "\n",
        "print(f\"\\nðŸ”¤ ExtracciÃ³n de informaciÃ³n:\")\n",
        "print(f\"  - CaracterÃ­sticas NLP extraÃ­das: {nlp_features_count}\")\n",
        "print(f\"  - TÃ©cnicas aplicadas: AnÃ¡lisis de sentimientos, NER, caracterÃ­sticas textuales\")\n",
        "\n",
        "# Resumen de modelos\n",
        "models_trained = len([r for r in ml_results.values() if r is not None])\n",
        "models_above_threshold = len([r for r in ml_results.values() \n",
        "                             if r is not None and r['f1_score'] > 0.78])\n",
        "\n",
        "print(f\"\\nðŸ¤– Modelos de Machine Learning:\")\n",
        "print(f\"  - Modelos entrenados: {models_trained}\")\n",
        "print(f\"  - Modelos con F1 > 0.78: {models_above_threshold}\")\n",
        "print(f\"  - Mejor modelo: {best_model_name} (F1: {best_score:.4f})\")\n",
        "\n",
        "# Recomendaciones\n",
        "print(f\"\\nðŸ’¡ RECOMENDACIONES:\")\n",
        "if best_score > 0.78:\n",
        "    print(\"âœ… El modelo cumple el objetivo de F1 > 0.78\")\n",
        "    print(\"âœ… La extracciÃ³n de informaciÃ³n fue exitosa\")\n",
        "    print(\"âœ… El pipeline de limpieza funcionÃ³ correctamente\")\n",
        "else:\n",
        "    print(\"âš ï¸ Considerar mÃ¡s caracterÃ­sticas o datos para mejorar rendimiento\")\n",
        "    print(\"âš ï¸ Evaluar tÃ©cnicas adicionales de NLP\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ ESTADO DEL PROYECTO: {'EXITOSO' if best_score > 0.78 else 'REQUIERE MEJORAS'}\")\n",
        "print(\"ðŸ“ Todos los resultados estÃ¡n disponibles en el objeto 'classifier'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === ALTERNATIVA: EJECUCIÃ“N RÃPIDA CON UNA LÃNEA ===\n",
        "\n",
        "print(\"âš¡ OPCIÃ“N RÃPIDA: Ejecutar todo el anÃ¡lisis automÃ¡ticamente\")\n",
        "print(\"Descomenta la lÃ­nea siguiente para ejecutar todo de una vez:\")\n",
        "\n",
        "# from modules import quick_start\n",
        "# analyzer, results = quick_start('ted_talks_en.csv')\n",
        "\n",
        "print(\"\\nðŸ’¡ Esta opciÃ³n ejecuta automÃ¡ticamente:\")\n",
        "print(\"  1. ConfiguraciÃ³n del ambiente\")\n",
        "print(\"  2. Carga y limpieza de datos\") \n",
        "print(\"  3. ExtracciÃ³n de informaciÃ³n NLP\")\n",
        "print(\"  4. Entrenamiento de modelos ML\")\n",
        "print(\"  5. Visualizaciones y mÃ©tricas\")\n",
        "print(\"  6. Conclusiones\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ Resultado esperado: F1-score > 0.78 en el mejor modelo\")\n",
        "print(\"ðŸ“Š Todo optimizado para extracciÃ³n de informaciÃ³n de ted_talks_en.csv\")"
      ]
    }
  ],
  "metadata": {
    "deepnote_notebook_id": "9ef24892143a426ca3c75c3ddd0a2b31",
    "kernelspec": {
      "display_name": "cloudspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
